{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image pairs in the dataset: 425\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CTScanPairDataset' object has no attribute 'files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     75\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStarting epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mfor\u001b[39;00m i, (fixed_image, moving_image) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset):\n\u001b[0;32m     77\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     78\u001b[0m         y_pred, _ \u001b[39m=\u001b[39m model(moving_image\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), fixed_image\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n",
      "Cell \u001b[1;32mIn[32], line 33\u001b[0m, in \u001b[0;36mCTScanPairDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m---> 33\u001b[0m      image \u001b[39m=\u001b[39m sitk\u001b[39m.\u001b[39mReadImage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfiles[idx])\n\u001b[0;32m     34\u001b[0m      image_array \u001b[39m=\u001b[39m sitk\u001b[39m.\u001b[39mGetArrayFromImage(image)\n\u001b[0;32m     35\u001b[0m      image_array \u001b[39m=\u001b[39m (image_array \u001b[39m-\u001b[39m image_array\u001b[39m.\u001b[39mmin()) \u001b[39m/\u001b[39m (image_array\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m image_array\u001b[39m.\u001b[39mmin())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CTScanPairDataset' object has no attribute 'files'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import ipyvolume as ipv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage import map_coordinates\n",
    "from voxelmorph.torch.networks import VxmDense\n",
    "from torch.optim import Adam\n",
    "\n",
    "class CTScanDataset(Dataset):\n",
    "    def __init__(self, directory_path):\n",
    "        self.files = [os.path.join(directory_path, f) for f in os.listdir(directory_path)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = sitk.ReadImage(self.files[idx])\n",
    "        image_array = sitk.GetArrayFromImage(image)\n",
    "        image_array = (image_array - image_array.min()) / (image_array.max() - image_array.min())\n",
    "        return image_array\n",
    "\n",
    "\n",
    "class CTScanPairDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         image = sitk.ReadImage(self.files[idx])\n",
    "         image_array = sitk.GetArrayFromImage(image)\n",
    "         image_array = (image_array - image_array.min()) / (image_array.max() - image_array.min())\n",
    "         # Ensure the output is (channel, depth, height, width)\n",
    "         return np.expand_dims(image_array, axis=0)\n",
    "\n",
    "def load_data_for_training(directory_path):\n",
    "    dataset = CTScanDataset(directory_path)\n",
    "    pairs = [(dataset[i], dataset[i + 1]) for i in range(len(dataset) - 1)]\n",
    "    return CTScanPairDataset(pairs)\n",
    "\n",
    "def preprocess(image_array):\n",
    "    # Ensure the output is (channel, depth, height, width)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    return image_tensor\n",
    "\n",
    "def apply_displacement_field(moving_image_array, displacement_field):\n",
    "    coords = np.mgrid[0:moving_image_array.shape[0], 0:moving_image_array.shape[1], 0:moving_image_array.shape[2]]\n",
    "    coords += displacement_field\n",
    "    warped_moving_image_array = map_coordinates(moving_image_array, coords, order=3)\n",
    "    return warped_moving_image_array\n",
    "\n",
    "def display_images(image_array):\n",
    "    ipv.figure()\n",
    "    ipv.volshow(image_array, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "    ipv.show()\n",
    "\n",
    "# Paths to the DICOM directories\n",
    "image_directory_path = r\"C:\\Users\\HP\\Documents\\GitHub\\3D-3D_Image_Registration\\SE000003\"\n",
    "\n",
    "# Load the DICOM images\n",
    "dataset = load_data_for_training(image_directory_path)\n",
    "print(f\"Number of image pairs in the dataset: {len(dataset)}\")\n",
    "\n",
    "## Initialize the model and optimizer\n",
    "model = VxmDense(inshape=(256, 256, 256), nb_unet_features=[[32, 64, 128, 256, 512], [512, 256, 128, 64, 32]])\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch + 1}')\n",
    "    for i, (fixed_image, moving_image) in enumerate(dataset):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _ = model(moving_image.float().unsqueeze(0), fixed_image.float().unsqueeze(0))\n",
    "        loss = torch.nn.MSELoss()(y_pred, fixed_image.float().unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save the model\n",
    "model_save_path = r\"C:\\Users\\HP\\Documents\\GitHub\\3D-3D_Image_Registration\\model.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Load the model and apply it to a pair of images for visualization\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Choose a pair of images to register and visualize\n",
    "fixed_image_tensor, moving_image_tensor = dataset[0]  # Change index if necessary\n",
    "\n",
    "# Compute the displacement field\n",
    "displacement_field, _ = model([fixed_image_tensor.float().unsqueeze(0), moving_image_tensor.float().unsqueeze(0)])\n",
    "\n",
    "# Convert displacement field back to numpy\n",
    "displacement_field = displacement_field.detach().numpy()\n",
    "\n",
    "# Apply displacement field to moving image\n",
    "warped_moving_image_array = apply_displacement_field(moving_image_tensor.numpy(), displacement_field)\n",
    "\n",
    "# Display the images after transformation\n",
    "display_images(fixed_image_tensor.numpy().squeeze())\n",
    "display_images(warped_moving_image_array.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install voxelmorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
